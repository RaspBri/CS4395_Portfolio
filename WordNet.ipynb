{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What is WordNet?"
      ],
      "metadata": {
        "id": "TEizVwAZ_m1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet is part of the NLTK corpus database which allows for Python users to find definitions, hypernyms, and antonyms of words. It is very powerful which makes it helpful for text analysis within databases. A downside to WordNet is that it does not support contraction words.\n"
      ],
      "metadata": {
        "id": "Vve4sWrFAuMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOUN"
      ],
      "metadata": {
        "id": "5snYAwuFAhQh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51M_WFDsAbuO",
        "outputId": "01494262-4ea7-4c4d-a300-25bb80f495a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.wsd import lesk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('paper') # output all synsets of noun"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoliitLaBKII",
        "outputId": "1251579d-e7b8-4734-8f4c-bf3ee82ad2f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('paper.n.01'),\n",
              " Synset('composition.n.08'),\n",
              " Synset('newspaper.n.01'),\n",
              " Synset('paper.n.04'),\n",
              " Synset('paper.n.05'),\n",
              " Synset('newspaper.n.02'),\n",
              " Synset('newspaper.n.03'),\n",
              " Synset('paper.v.01'),\n",
              " Synset('wallpaper.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper = wn.synset('paper.n.05')\n",
        "wn.synset('paper.n.05').definition() # definition of synset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "WyPfcgfNDTxs",
        "outputId": "b6658dac-2e2a-44f5-e10b-23f8c1a12919"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a scholarly article describing the results of observations or stating hypotheses'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('paper.n.05').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMnUcZSxDjAM",
        "outputId": "d6443d0c-8fbd-4114-d75f-1f47c6d6fcd6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he has written many scientific papers']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('paper.n.05').lemmas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3C17aThDkEM",
        "outputId": "5185e931-e45b-48f7-8418-1d8f6c78fba2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('paper.n.05.paper')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# traverse wordnet output all synsets possible\n",
        "paper_synsets = wn.synsets('paper', pos = wn.NOUN)\n",
        "for sense in paper_synsets:\n",
        "  lemmas = [l.name() for l in sense.lemmas()]\n",
        "  print(\"Synset: \" + sense.name() + \"(\" + sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d1CcexLlJW0",
        "outputId": "f74cb526-7c2d-42f3-8e4b-7dd0e2b4608a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: paper.n.01(a material made of cellulose pulp derived mainly from wood or rags or certain grasses)  \n",
            "\t Lemmas:['paper']\n",
            "Synset: composition.n.08(an essay (especially one written as an assignment))  \n",
            "\t Lemmas:['composition', 'paper', 'report', 'theme']\n",
            "Synset: newspaper.n.01(a daily or weekly publication on folded sheets; contains news and articles and advertisements)  \n",
            "\t Lemmas:['newspaper', 'paper']\n",
            "Synset: paper.n.04(a medium for written communication)  \n",
            "\t Lemmas:['paper']\n",
            "Synset: paper.n.05(a scholarly article describing the results of observations or stating hypotheses)  \n",
            "\t Lemmas:['paper']\n",
            "Synset: newspaper.n.02(a business firm that publishes newspapers)  \n",
            "\t Lemmas:['newspaper', 'paper', 'newspaper_publisher']\n",
            "Synset: newspaper.n.03(the physical object that is the product of a newspaper publisher)  \n",
            "\t Lemmas:['newspaper', 'paper']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the definitions for the chosen noun is ordered based on the frequency that the word is used. It seems like whatever frequency database WordNet is basing its results off of are aligned closely with academia because the second result is 'composition'. I do like that the first result was related to the exact definition I was intending for WordNet to use, paper as a material. It also seems like the words are organized based on how concrete to abstract the definitions of the word are. Also, the numbers assigned to these synsets are not in order."
      ],
      "metadata": {
        "id": "01bggiU0luhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOUN: hypernyms, hyponyms, meronyms,holonyms, antonym"
      ],
      "metadata": {
        "id": "gJV3twDNZfEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper.hypernyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB6tJwkEl5H0",
        "outputId": "1147f47e-b7a8-4a62-f3a4-b491f4c6321e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('article.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper.hyponyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCYhEV2NmvfM",
        "outputId": "0bbafbf5-a1c1-4b03-af38-e15973d73644"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper.member_meronyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAsSmtm0m8gv",
        "outputId": "3a2fe972-7c27-42e0-c5b5-4d7dbe6466dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper.member_holonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QC4pVCEnDgZ",
        "outputId": "30c52c39-f593-41b7-e089-053eeec6bcba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper.lemmas()[0].antonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX998bm_mySx",
        "outputId": "3ce6fd21-9fb1-4457-d06b-9ca14239da94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VERB"
      ],
      "metadata": {
        "id": "IlPkcgiqn5Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('spin') # output all synsets of spin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biIOtJKCn4zz",
        "outputId": "dcffd27e-5387-4ec5-b7e2-edc250aa3db9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('spin.n.01'),\n",
              " Synset('spin.n.02'),\n",
              " Synset('spin.n.03'),\n",
              " Synset('tailspin.n.02'),\n",
              " Synset('spin.n.05'),\n",
              " Synset('spin.v.01'),\n",
              " Synset('spin.v.02'),\n",
              " Synset('whirl.v.02'),\n",
              " Synset('spin.v.04'),\n",
              " Synset('spin.v.05'),\n",
              " Synset('spin.v.06'),\n",
              " Synset('spin.v.07'),\n",
              " Synset('spin.v.08')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spin = wn.synset('spin.n.03')\n",
        "wn.synset('spin.n.03').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "FpxhecPuoEZP",
        "outputId": "b796df1a-f612-4bf1-b4ab-6742e63d7ccd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a short drive in a car'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('spin.n.03').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6gDp_yLoQZw",
        "outputId": "652776d7-7201-4a26-fe5f-5bd2f139aa28"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he took the new car for a spin']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('spin.n.03').lemmas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLChIzIgoTvF",
        "outputId": "79873f9a-e72a-48c6-958b-f9dd9933bfed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('spin.n.03.spin')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Traverse wordnet output all synsets\n",
        "spin_synsets = wn.synsets('spin', pos = wn.VERB)\n",
        "for sense in spin_synsets:\n",
        "  lemmas = [l.name() for l in sense.lemmas()]\n",
        "  print(\"Synset: \" + sense.name() + \"(\" + sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Au7aIsJobCD",
        "outputId": "e2d5e26b-c673-4069-ef71-18812be83b87"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: spin.v.01(revolve quickly and repeatedly around one's own axis)  \n",
            "\t Lemmas:['spin', 'spin_around', 'whirl', 'reel', 'gyrate']\n",
            "Synset: spin.v.02(stream in jets, of liquids)  \n",
            "\t Lemmas:['spin']\n",
            "Synset: whirl.v.02(cause to spin)  \n",
            "\t Lemmas:['whirl', 'birl', 'spin', 'twirl']\n",
            "Synset: spin.v.04(make up a story)  \n",
            "\t Lemmas:['spin']\n",
            "Synset: spin.v.05(form a web by making a thread)  \n",
            "\t Lemmas:['spin']\n",
            "Synset: spin.v.06(work natural fibers into a thread)  \n",
            "\t Lemmas:['spin']\n",
            "Synset: spin.v.07(twist and turn so as to give an intended interpretation)  \n",
            "\t Lemmas:['spin']\n",
            "Synset: spin.v.08(prolong or extend)  \n",
            "\t Lemmas:['spin', 'spin_out']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the verbs it seems like WordNet is organizing them on the most commony used definition, similar to nouns. However, the numbers for these synsets are in order where as the noun were not. I found it interesting that spin.v.07 was listed much further below spin.v.04 when to me they seem to be very close in meaning as definitions. It seemed a bit odd to place them seperately as well, I would have assumed WordNet to choose one variation of the definition."
      ],
      "metadata": {
        "id": "Eb2caugwolwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('spin', wn.VERB) #morphy to find different forms of the word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "SEKGU-k_oznY",
        "outputId": "5b952e17-3c26-4205-deeb-bc4667aa6d19"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'spin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Similar Words"
      ],
      "metadata": {
        "id": "U4HeWHGcpZqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# allowed/permitted | allow/permit\n",
        "wn.synsets('allow') # output all synsets of allow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVY5FzTJpY1f",
        "outputId": "b906e437-379d-4363-a860-cf1b5810ecea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('let.v.01'),\n",
              " Synset('permit.v.01'),\n",
              " Synset('allow.v.03'),\n",
              " Synset('allow.v.04'),\n",
              " Synset('leave.v.06'),\n",
              " Synset('allow.v.06'),\n",
              " Synset('admit.v.05'),\n",
              " Synset('give_up.v.11'),\n",
              " Synset('allow.v.09'),\n",
              " Synset('allow.v.10')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('permit') # output all synsets of permit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbLBIGuRqTmQ",
        "outputId": "8e7cd53c-e863-4fcd-c5fb-77c05ce5bf20"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('license.n.01'),\n",
              " Synset('license.n.04'),\n",
              " Synset('permit.n.03'),\n",
              " Synset('permit.v.01'),\n",
              " Synset('let.v.01'),\n",
              " Synset('allow.v.10')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allow = wn.synset('allow.v.10') # chosen sysnet\n",
        "wn.synset('allow.v.10').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "bzddXnXaqaXG",
        "outputId": "53d7b360-70be-45a6-bb6a-86082d2c2eb4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'allow the presence of or allow (an activity) without opposing or prohibiting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permit = wn.synset('permit.v.01') # chosen synset\n",
        "wn.synset('permit.v.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "5GZgbLbkqfOm",
        "outputId": "c519a06d-fb88-4570-d158-66c09330bd64"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'consent to, give permission'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.wup_similarity(allow, permit) # Wu-Palmer result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGdJgPwgrgxe",
        "outputId": "ff5fbc47-a24e-4ac7-9a30-cc8411521c9f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lesk Alg"
      ],
      "metadata": {
        "id": "GWrGUIjjfF5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lesk algorithm for \"allow\"\n",
        "for ss in wn.synsets('allow'):\n",
        "    print(ss, ss.definition())\n",
        "sent1 = ['I', 'will', 'allow', 'it', '.']\n",
        "print(lesk(sent1, 'allow', 'v'))\n",
        "print(lesk(sent1, 'allow'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajMt5BR2rtWx",
        "outputId": "d3b1875e-3235-4819-d5f9-d0f91e22c43f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('let.v.01') make it possible through a specific action or lack of action for something to happen\n",
            "Synset('permit.v.01') consent to, give permission\n",
            "Synset('allow.v.03') let have\n",
            "Synset('allow.v.04') give or assign a resource to a particular person or cause\n",
            "Synset('leave.v.06') make a possibility or provide opportunity for; permit to be attainable or cause to remain\n",
            "Synset('allow.v.06') allow or plan for a certain possibility; concede the truth or validity of something\n",
            "Synset('admit.v.05') afford possibility\n",
            "Synset('give_up.v.11') allow the other (baseball) team to score\n",
            "Synset('allow.v.09') grant as a discount or in exchange\n",
            "Synset('allow.v.10') allow the presence of or allow (an activity) without opposing or prohibiting\n",
            "Synset('let.v.01')\n",
            "Synset('let.v.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lesk algorithm for \"permit\"\n",
        "for ss in wn.synsets('permit'):\n",
        "    print(ss, ss.definition())\n",
        "sent2 = ['I', 'will', 'permit', 'it', '.']\n",
        "print(lesk(sent1, 'permit', 'v'))\n",
        "print(lesk(sent1, 'permit'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J19H6zh4LhS-",
        "outputId": "dd8e8111-a7c2-4c75-a97d-3fdd0da221dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('license.n.01') a legal document giving official permission to do something\n",
            "Synset('license.n.04') the act of giving a formal (usually written) authorization\n",
            "Synset('permit.n.03') large game fish; found in waters of the West Indies\n",
            "Synset('permit.v.01') consent to, give permission\n",
            "Synset('let.v.01') make it possible through a specific action or lack of action for something to happen\n",
            "Synset('allow.v.10') allow the presence of or allow (an activity) without opposing or prohibiting\n",
            "Synset('let.v.01')\n",
            "Synset('let.v.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Wu-Palmer similarity metric was easier to execute than the Lesk algorithm because it only took one line. The Wu-Palmer metric gave me a number I was happy with, 88%. I agree with the results and believe that if I had picked possibly a different combination of the definitions the percentage could have been higher. I think the Lesk algorithm results would have given the two words a 100% rating for similarity if it could have given a metric because I ended up getting the same resutls for both words, let.v.01. I think that if I had used a different sentence for each word using the Lesk algorithm I would have gotten different results depending on the vairability of the provided sentence. \n"
      ],
      "metadata": {
        "id": "hcEqucsLLyzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lesk(sent2, 'permit', pos = 'a'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mE2fLAvLtlu",
        "outputId": "f7454509-8356-4840-c14b-9bac057505f6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SentiWordNet"
      ],
      "metadata": {
        "id": "qf57aKvafLZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet is used for getting the emotional range of a given sentence such as positive, negative, or neutral. It takes in full sentences, not words, to analyze. SentiWordNet will provide its results as a decimal that has a range from 0 to 1. This can be used by chatbots to determine how a person is feeling during the automated assistance process."
      ],
      "metadata": {
        "id": "Bcyfb-v0RJBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Must import senti-synset\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "nltk.download('sentiwordnet')\n",
        "#wn.synsets('joy')\n",
        "joy = swn.senti_synset('fantastic.s.02')\n",
        "print(joy)\n",
        "print(\"Positive score: \", joy.pos_score())\n",
        "print(\"Negative score: \", joy.neg_score())\n",
        "print(\"Objective score: \", joy.obj_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE594YBvL01A",
        "outputId": "324c3c3b-cc49-446d-d415-9c990da26937"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<fantastic.s.02: PosScore=0.75 NegScore=0.0>\n",
            "Positive score:  0.75\n",
            "Negative score:  0.0\n",
            "Objective score:  0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_joy = 'I am very excited for this weekend!'\n",
        "# using the word 'very' makes the results more positive than using \n",
        "# the word 'so' or just putting a space\n",
        "negative = 0\n",
        "positive = 0\n",
        "tokens = sentence_joy.split()\n",
        "for token in tokens:\n",
        "  syn_list = list(swn.senti_synsets(token))\n",
        "  if syn_list:\n",
        "    syn = syn_list[0]\n",
        "    negative += syn.neg_score()\n",
        "    positive += syn.pos_score()\n",
        "\n",
        "print('-', '\\t', '+')\n",
        "print(negative, '\\t', positive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfD7rjg4QBs2",
        "outputId": "6df78edd-3659-4736-f4ae-411762513471"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- \t +\n",
            "0.375 \t 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think that these scores are a bit off because, I believe the positivity score should have been higher. Perhaps in the 0.8 or 0.9 range with the negativity score being 0.1 or 0.2. I also noticed that when I added the word 'very' the results became more positive compared to when I used the word 'so.'  Also, when I did not include any word of emphasis the positivity score also decreased."
      ],
      "metadata": {
        "id": "s2_lct0PRMJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collocation"
      ],
      "metadata": {
        "id": "J_u06CYnfSx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('treebank')\n",
        "nltk.download('webtext')\n",
        "nltk.download('stopwords')\n",
        "from nltk.book import *\n",
        "from nltk.collocations import *\n",
        "text4.collocations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvrolKL4RQzI",
        "outputId": "1ae27b9c-1624-4238-cf67-6e016368d317"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/webtext.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n",
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocation is based on the closeness of a word with another word based on frequency. It is the most common with nouns and verbs being next to each other, or even adjectives and nouns together. An example of a common collocation is \"lions roar.\" Also, collocations help with giving a better full picture of what the speaker is trying to protray to the listener. With these extra details (AKA collocations) the person listening is in a better position to respond approprately to what the speaker said. "
      ],
      "metadata": {
        "id": "J_cDPXsAITGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(text4.tokens)\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "-U51G3Fc7w8O",
        "outputId": "1989510a-1ac8-4878-a904-693db19f3f54"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fellow - Citizens of the Senate and of the House of Representatives : Among the vicissitudes inciden'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "vocab = len(set(text4))\n",
        "\n",
        "hg = text.count('Chief Justice')/vocab\n",
        "print(\"p(Chief Justice) = \",hg )\n",
        "h = text.count('Chief')/vocab\n",
        "print(\"p(Chief) = \", h)\n",
        "g = text.count('Justice')/vocab\n",
        "print('p(Justice) = ', g)\n",
        "pmi = math.log2(hg / (h * g))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXQ5q1VV81QG",
        "outputId": "f091a564-bc8c-4e10-b9ff-1fcabf2d46e4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(Chief Justice) =  0.001396508728179551\n",
            "p(Chief) =  0.002793017456359102\n",
            "p(Justice) =  0.002394014962593516\n",
            "pmi =  7.706352115508489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of the collocation mutual information values were not very impressive to me. I was dissapointed because, I figured the words 'Chief Justice' would appear more frequently together. It seems like the two words appeared more frequently independantly that as a joint pairing. "
      ],
      "metadata": {
        "id": "W5a2MWqd9gzs"
      }
    }
  ]
}